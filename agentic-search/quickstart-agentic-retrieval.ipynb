{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4be5d807",
   "metadata": {},
   "source": [
    "# クイックスタート: Azure AI Search でのエージェント検索\n",
    "\n",
    "このノートブックを使用して、Azure AI Search の[エージェント検索](https://learn.microsoft.com/azure/search/search-agentic-retrieval-concept)を開始しましょう。エージェント検索は会話履歴と Azure OpenAI の大規模言語モデル（LLM）を統合して、複雑なクエリの計画、検索、合成を行います。\n",
    "\n",
    "このノートブックの手順:\n",
    "\n",
    "+ `earth_at_night` 検索インデックスの作成\n",
    "\n",
    "+ GitHub URL からのドキュメントをインデックスに読み込み\n",
    "\n",
    "+ クエリ計画のためのLLMを指す `earth-search-agent` をAzure AI Searchで作成\n",
    "\n",
    "+ エージェントを使用してインデックスから関連情報を取得しランキング\n",
    "\n",
    "+ Azure OpenAI クライアントを使用した回答生成\n",
    "\n",
    "このノートブックはエージェント検索の高レベルなデモを提供します。詳細なガイダンスについては、[クイックスタート: Azure AI Search でエージェント検索を実行する](https://learn.microsoft.com/azure/search/search-get-started-agentic-retrieval)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712b97d",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "+ [セマンティックランカーが有効](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable)になっている Basic 以上のティアの [Azure AI Search サービス](https://learn.microsoft.com/azure/search/search-create-service-portal)\n",
    "\n",
    "+ [Azure OpenAI リソース](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource)\n",
    "\n",
    "+ Azure OpenAI リソースにデプロイされた[サポートされているモデル](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-create#supported-models)。このノートブックでは `gpt-4.1-mini` を使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5fbd46",
   "metadata": {},
   "source": [
    "## アクセス設定\n",
    "\n",
    "このノートブックは Microsoft Entra ID とロール割り当てを使用した認証と認可を前提としています。また、ローカルデバイスからコードを実行することも想定しています。\n",
    "\n",
    "ロールベースアクセスを設定するには:\n",
    "\n",
    "1. [Azure ポータル](https://portal.azure.com)にサインインします。\n",
    "\n",
    "1. Azure AI Search サービスで[ロールベースアクセスを有効](https://learn.microsoft.com/azure/search/search-security-enable-roles)にします。\n",
    "\n",
    "1. Azure AI Search サービスで[システム割り当てマネージド ID を作成](https://learn.microsoft.com/azure/search/search-howto-managed-identities-data-sources#create-a-system-managed-identity)します。\n",
    "\n",
    "1. Azure AI Search サービスで、自分に[次のロールを割り当て](https://learn.microsoft.com/azure/search/search-security-rbac#how-to-assign-roles-in-the-azure-portal)ます。\n",
    "\n",
    "   + **Search Service Contributor**\n",
    "\n",
    "   + **Search Index Data Contributor**\n",
    "\n",
    "   + **Search Index Data Reader**\n",
    "\n",
    "1. Azure OpenAI リソースで、検索サービスのマネージド ID に **Cognitive Services User** を割り当てます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bf308",
   "metadata": {},
   "source": [
    "## 接続設定\n",
    "\n",
    "`sample.env` ファイルには、Azure AI Search と Azure OpenAI への接続用の環境変数が含まれています。エージェント検索には、ドキュメント検索、クエリ計画、クエリ実行、回答生成のためにこれらの接続が必要です。\n",
    "\n",
    "接続を設定するには:\n",
    "\n",
    "1. [Azure ポータル](https://portal.azure.com)にサインインします。\n",
    "\n",
    "2. Azure AI Search と Azure OpenAI の両方のエンドポイントを取得します。\n",
    "\n",
    "3. `sample.env` ファイルをローカルデバイスに `.env` として保存します。\n",
    "\n",
    "4. 取得したエンドポイントで `.env` ファイルを更新します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a54a0f",
   "metadata": {},
   "source": [
    "## 仮想環境の作成\n",
    "\n",
    "`requirements.txt` ファイルには、このノートブックの依存関係が含まれています。仮想環境を使用して、これらの依存関係を分離してインストールできます。\n",
    "\n",
    "仮想環境を作成するには:\n",
    "\n",
    "1. Visual Studio Code で、`quickstart.ipynb` を含むフォルダを開きます。\n",
    "\n",
    "1. **Ctrl**+**Shift**+**P** を押してコマンドパレットを開きます。\n",
    "\n",
    "1. **Python: Create Environment** を検索し、**Venv** を選択します。\n",
    "\n",
    "1. Python インストールを選択します。このノートブックは Python 3.13 でテストしました。\n",
    "\n",
    "1. 依存関係として `requirements.txt` を選択します。\n",
    "\n",
    "仮想環境の作成には数分かかる場合があります。環境が準備できたら、次のステップに進みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714a968",
   "metadata": {},
   "source": [
    "## パッケージのインストールと接続の読み込み\n",
    "\n",
    "このステップでは、このノートブック用のパッケージをインストールし、Azure AI Search と Azure OpenAI への接続を確立します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42506658",
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # Take environment variables from .env.\n",
    "\n",
    "# The following variables from your .env file are used in this notebook\n",
    "answer_model = os.getenv(\"ANSWER_MODEL\", \"gpt-4.1-mini\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://search.azure.com/.default\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth_at_night_4\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_gpt_deployment = os.getenv(\"AZURE_OPENAI_GPT_DEPLOYMENT\", \"gpt-4.1-mini\")\n",
    "azure_openai_gpt_model = os.getenv(\"AZURE_OPENAI_GPT_MODEL\", \"gpt-4.1-mini\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-03-01-preview\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "agent_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-search-agent-4\")\n",
    "api_version = \"2025-05-01-Preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8a088",
   "metadata": {},
   "source": [
    "## Azure AI Search でのインデックス作成\n",
    "\n",
    "このステップでは、プレーンテキストとベクターコンテンツを含む検索インデックスを作成します。既存のインデックスを使用することもできますが、[エージェント検索ワークロード](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-index)の基準を満たす必要があります。主要なスキーマ要件は、`default_configuration_name` を持つセマンティック設定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import SearchIndex, SearchField, VectorSearch, VectorSearchProfile, HnswAlgorithmConfiguration, AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters, SemanticSearch, SemanticConfiguration, SemanticPrioritizedFields, SemanticField\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(name=\"page_embedding_text_3_large\", type=\"Collection(Edm.Single)\", stored=False, vector_search_dimensions=3072, vector_search_profile_name=\"hnsw_text_3_large\"),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True)\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(name=\"hnsw_text_3_large\", algorithm_configuration_name=\"alg\", vectorizer_name=\"azure_openai_text_3_large\")],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[\n",
    "                        SemanticField(field_name=\"page_chunk\")\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_name}' created or updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39874f61",
   "metadata": {},
   "source": [
    "## サンプルドキュメントのアップロード\n",
    "\n",
    "このノートブックは NASA の「Earth at Night」電子書籍のデータを使用します。データは GitHub の [azure-search-sample-data](https://github.com/Azure-Samples/azure-search-sample-data) リポジトリから取得され、インデックス化のために検索クライアントに渡されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/refs/heads/main/nasa-e-book/earth-at-night-json/documents.json\"\n",
    "documents = requests.get(url).json()\n",
    "\n",
    "with SearchIndexingBufferedSender(endpoint=endpoint, index_name=index_name, credential=credential) as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"Documents uploaded to index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e0a34",
   "metadata": {},
   "source": [
    "## Azure AI Search でのエージェント作成\n",
    "\n",
    "このステップでは、Azure OpenAI にデプロイした LLM のラッパーとして機能するナレッジエージェントを作成します。LLM はエージェント検索パイプラインにクエリを送信するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeAgent, KnowledgeAgentAzureOpenAIModel, KnowledgeAgentTargetIndex, KnowledgeAgentRequestLimits, AzureOpenAIVectorizerParameters\n",
    "\n",
    "agent = KnowledgeAgent(\n",
    "    name=agent_name,\n",
    "    models=[\n",
    "        KnowledgeAgentAzureOpenAIModel(\n",
    "            azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_gpt_deployment,\n",
    "                model_name=azure_openai_gpt_model\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    target_indexes=[\n",
    "        KnowledgeAgentTargetIndex(\n",
    "            index_name=index_name,\n",
    "            default_reranker_threshold=2.5\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "index_client.create_or_update_agent(agent)\n",
    "print(f\"Knowledge agent '{agent_name}' created or updated successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610cefd",
   "metadata": {},
   "source": [
    "## メッセージの設定\n",
    "\n",
    "メッセージは検索ルートの入力で、会話履歴を含みます。各メッセージには、`assistant` や `user` など起源を示す `role` と、自然言語での `content` が含まれます。使用する LLM によって有効なロールが決まります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "A Q&A agent that can answer questions about the Earth at night.\n",
    "Sources have a JSON format with a ref_id that must be cited in the answer.\n",
    "If you do not have the answer, respond with \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": instructions\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090707f",
   "metadata": {},
   "source": [
    "## エージェント検索を使用した結果の取得\n",
    "\n",
    "このステップでは、検索インデックスから関連情報を抽出するために検索パイプラインを実行します。検索リクエストのメッセージとパラメータに基づいて、LLM は:\n",
    "\n",
    "1. 会話履歴全体を分析して、根本的な情報ニーズを判断します。\n",
    "\n",
    "1. 複合ユーザークエリを焦点を絞ったサブクエリに分解します。\n",
    " \n",
    "1. 各サブクエリを同時に、インデックスのテキストフィールドとベクター埋め込みに対して実行します。\n",
    "\n",
    "1. セマンティックランカーを使用して、すべてのサブクエリの結果を再ランク付けします。\n",
    "\n",
    "1. 結果を単一の文字列にマージします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ded26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, KnowledgeAgentIndexParams\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=agent_name, credential=credential)\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"\n",
    "    ダウンタウンの方が絶対的な光量が多いにもかかわらず、郊外のベルト地帯の方が都市の中心部よりも12月の輝度が高いのはなぜか？\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "retrieval_result = agent_client.retrieve(\n",
    "    retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "        messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg[\"content\"])]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "        target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2)]\n",
    "    )\n",
    ")\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": retrieval_result.response[0].content[0].text\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886fc687",
   "metadata": {},
   "source": [
    "### 検索レスポンス、アクティビティ、結果のレビュー\n",
    "\n",
    "Azure AI Search からの各検索レスポンスには以下が含まれます:\n",
    "\n",
    "+ 検索結果からのグラウンディングデータを表す統一文字列\n",
    "\n",
    "+ クエリ計画\n",
    "\n",
    "+ ソースドキュメントのどの部分が統一文字列に貢献したかを示す参照データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d78fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "print(\"Response\")\n",
    "print(textwrap.fill(retrieval_result.response[0].content[0].text, width=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccf4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(\"Activity\")\n",
    "print(json.dumps([a.as_dict() for a in retrieval_result.activity], indent=2))\n",
    "print(\"Results\")\n",
    "print(json.dumps([r.as_dict() for r in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75386ed1",
   "metadata": {},
   "source": [
    "## Azure OpenAI クライアントの作成\n",
    "\n",
    "ここまで、このノートブックは回答*抽出*のためにエージェント検索を使用してきました。Azure OpenAI クライアントを使用することで、これを回答*生成*まで拡張できます。これにより、インデックス化されたコンテンツに厳密に結びつかない、より詳細でコンテキストに富んだレスポンスが可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da260539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "azure_openai_token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_ad_token_provider=azure_openai_token_provider,\n",
    "    api_version=azure_openai_api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200bc2a",
   "metadata": {},
   "source": [
    "### Responses API を使用した回答生成\n",
    "\n",
    "回答生成の一つの選択肢は Responses API で、これは会話履歴を処理のために LLM に渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dea5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=answer_model,\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "wrapped = textwrap.fill(response.output_text, width=100)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dc5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c63f0",
   "metadata": {},
   "source": [
    "### Chat Completions API を使用した回答生成\n",
    "\n",
    "代替として、回答生成に Chat Completions API を使用することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=answer_model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "wrapped = textwrap.fill(response.choices[0].message.content, width=100)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0502d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96436b",
   "metadata": {},
   "source": [
    "## 会話の継続\n",
    "\n",
    "このステップでは、ナレッジエージェントとの会話を継続し、前のメッセージとクエリに基づいて、検索インデックスから関連情報を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"How do I find lava at night?\"\n",
    "})\n",
    "\n",
    "retrieval_result = agent_client.retrieve(\n",
    "    retrieval_request=KnowledgeAgentRetrievalRequest(\n",
    "        messages=[KnowledgeAgentMessage(role=msg[\"role\"], content=[KnowledgeAgentMessageTextContent(text=msg[\"content\"])]) for msg in messages if msg[\"role\"] != \"system\"],\n",
    "        target_index_params=[KnowledgeAgentIndexParams(index_name=index_name, reranker_threshold=2.5)]\n",
    "    )\n",
    ")\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": retrieval_result.response[0].content[0].text\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1cba0c",
   "metadata": {},
   "source": [
    "### 検索レスポンス、アクティビティ、結果のレビュー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Response\")\n",
    "print(textwrap.fill(retrieval_result.response[0].content[0].text, width=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(\"Activity\")\n",
    "print(json.dumps([a.as_dict() for a in retrieval_result.activity], indent=2))\n",
    "print(\"Results\")\n",
    "print(json.dumps([r.as_dict() for r in retrieval_result.references], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d32cc",
   "metadata": {},
   "source": [
    "## 回答生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6486c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=answer_model,\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "wrapped = textwrap.fill(response.output_text, width=100)\n",
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75777ed2",
   "metadata": {},
   "source": [
    "## オブジェクトとリソースのクリーンアップ\n",
    "\n",
    "Azure AI Search や Azure OpenAI が不要になった場合は、Azure サブスクリプションから削除してください。個別のオブジェクトを削除して最初からやり直すこともできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f6fe6",
   "metadata": {},
   "source": [
    "### ナレッジエージェントの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_agent(agent_name)\n",
    "print(f\"Knowledge agent '{agent_name}' deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35bfbb1",
   "metadata": {},
   "source": [
    "### 検索インデックスの削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.delete_index(index)\n",
    "print(f\"Index '{index_name}' deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
